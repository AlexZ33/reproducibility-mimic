{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import psycopg2\n",
    "import sys\n",
    "import datetime as dt\n",
    "import mp_utils as mp\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# used to print out pretty pandas dataframes\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# used to impute mean for data and standardize for computational stability\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression is our favourite model ever\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV # l2 regularized regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# used to calculate AUROC/accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# gradient boosting - must download package https://github.com/dmlc/xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.font_manager import FontProperties # for unicode fonts\n",
    "#%matplotlib inline\n",
    "\n",
    "# below config used on pc70\n",
    "sqluser = 'alistairewj'\n",
    "dbname = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "query_schema = 'SET search_path to public,' + schema_name + ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_SQL=0\n",
    "\n",
    "if USE_SQL:\n",
    "    # Connect to local postgres version of mimic\n",
    "    con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "\n",
    "    # exclusion criteria:\n",
    "    #   - less than 15 years old\n",
    "    #   - stayed in the ICU less than 4 hours\n",
    "    #   - never have any chartevents data (i.e. likely administrative error)\n",
    "    #   - organ donor accounts (administrative \"readmissions\" for patients who died in hospital)\n",
    "    query = query_schema + \\\n",
    "    \"\"\"\n",
    "    select \n",
    "        *\n",
    "    from dm_cohort\n",
    "    \"\"\"\n",
    "    co = pd.read_sql_query(query,con)\n",
    "    \n",
    "    # convert the inclusion flags to boolean\n",
    "    for c in co.columns:\n",
    "        if c[0:10]=='inclusion_':\n",
    "            co[c] = co[c].astype(bool)\n",
    "\n",
    "    # extract static vars into a separate dataframe\n",
    "    df_static = pd.read_sql_query(query_schema + 'select * from mp_static_data', con)\n",
    "    #for dtvar in ['intime','outtime','deathtime']:\n",
    "    #    df_static[dtvar] = pd.to_datetime(df_static[dtvar])\n",
    "\n",
    "    vars_static = [u'is_male', u'emergency_admission', u'age',\n",
    "                   # services\n",
    "                   u'service_any_noncard_surg',\n",
    "                   u'service_any_card_surg',\n",
    "                   u'service_cmed',\n",
    "                   u'service_traum',\n",
    "                   u'service_nmed',\n",
    "                   # ethnicities\n",
    "                   u'race_black',u'race_hispanic',u'race_asian',u'race_other',\n",
    "                   # phatness\n",
    "                   u'height', u'weight', u'bmi']\n",
    "\n",
    "\n",
    "    # get ~5 million rows containing data from errbody\n",
    "    # this takes a little bit of time to load into memory (~2 minutes)\n",
    "\n",
    "    # %%time results\n",
    "    # CPU times: user 42.8 s, sys: 1min 3s, total: 1min 46s\n",
    "    # Wall time: 2min 7s\n",
    "\n",
    "    df = pd.read_sql_query(query_schema + 'select * from mp_data', con)\n",
    "    df.drop('subject_id',axis=1,inplace=True)\n",
    "    df.drop('hadm_id',axis=1,inplace=True)\n",
    "    df.sort_values(['icustay_id','hr'],axis=0,ascending=True,inplace=True)\n",
    "    print(df.shape)\n",
    "\n",
    "    # get death information\n",
    "    df_death = pd.read_sql_query(query_schema + \"\"\"\n",
    "    select \n",
    "    co.subject_id, co.hadm_id, co.icustay_id\n",
    "    , ceil(extract(epoch from (co.outtime - co.intime))/60.0/60.0) as dischtime_hours\n",
    "    , ceil(extract(epoch from (adm.deathtime - co.intime))/60.0/60.0) as deathtime_hours\n",
    "    , case when adm.deathtime is null then 0 else 1 end as death\n",
    "    from dm_cohort co\n",
    "    inner join admissions adm\n",
    "    on co.hadm_id = adm.hadm_id\n",
    "    where co.excluded = 0\n",
    "    \"\"\", con)\n",
    "    \n",
    "    # get censoring information\n",
    "    df_censor = pd.read_sql_query(query_schema + \"\"\"\n",
    "    select co.icustay_id, min(cs.charttime) as censortime\n",
    "    , ceil(extract(epoch from min(cs.charttime-co.intime) )/60.0/60.0) as censortime_hours\n",
    "    from dm_cohort co \n",
    "    inner join mp_code_status cs\n",
    "    on co.icustay_id = cs.icustay_id\n",
    "    where cmo+dnr+dni+dncpr+cmo_notes>0\n",
    "    and co.excluded = 0\n",
    "    group by co.icustay_id\n",
    "    \"\"\", con)\n",
    "\n",
    "    # get severity scores\n",
    "    df_soi = pd.read_sql_query(query_schema + \"\"\"\n",
    "    select \n",
    "    co.icustay_id\n",
    "    , case when adm.deathtime is null then 0 else 1 end as death\n",
    "    , sa.saps\n",
    "    , sa2.sapsii\n",
    "    , aps.apsiii\n",
    "    , so.sofa\n",
    "    , lo.lods\n",
    "    , oa.oasis\n",
    "    from dm_cohort co\n",
    "    inner join admissions adm\n",
    "    on co.hadm_id = adm.hadm_id\n",
    "    left join saps sa\n",
    "    on co.icustay_id = sa.icustay_id\n",
    "    left join sapsii sa2\n",
    "    on co.icustay_id = sa2.icustay_id\n",
    "    left join apsiii aps\n",
    "    on co.icustay_id = aps.icustay_id\n",
    "    left join sofa so\n",
    "    on co.icustay_id = so.icustay_id\n",
    "    left join lods lo\n",
    "    on co.icustay_id = lo.icustay_id\n",
    "    left join oasis oa\n",
    "    on co.icustay_id = oa.icustay_id\n",
    "    where co.excluded = 0\n",
    "    \"\"\", con)\n",
    "    \n",
    "    # extract static vars into a separate dataframe\n",
    "    df_static = pd.read_sql_query(query_schema + 'select * from mp_static_data', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "USE_CSV=1\n",
    "\n",
    "if USE_CSV:\n",
    "    co = pd.read_csv('df_cohort.csv.gz')\n",
    "    \n",
    "    # convert the inclusion flags to boolean\n",
    "    for c in co.columns:\n",
    "        if c[0:10]=='inclusion_':\n",
    "            co[c] = co[c].astype(bool)\n",
    "    df = pd.read_csv('df_data.csv.gz')\n",
    "    df_static = pd.read_csv('df_static_data.csv.gz')\n",
    "    df_censor = pd.read_csv('df_censor.csv.gz')\n",
    "    df_death = pd.read_csv('df_death.csv.gz')\n",
    "    df_soi = pd.read_csv('df_soi.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort - initial size: 61532 ICU stays\n",
      "   8101 (13.17%) - exclusion_over_15\n",
      "   1347 (2.19%) - exclusion_valid_data\n",
      "   3641 (5.92%) - exclusion_stay_lt_4hr\n",
      "      4 (0.01%) - exclusion_organ_donor\n",
      "   9447 (15.35%) - all exclusions\n",
      "\n",
      "Final cohort size: 52085 ICU stays (84.65%).\n"
     ]
    }
   ],
   "source": [
    "# print out the exclusions *SEQUENTIALLY* - i.e. if already excluded, don't re-print\n",
    "print('Cohort - initial size: {} ICU stays'.format(co.shape[0]))\n",
    "\n",
    "idxRem = np.zeros(co.shape[0],dtype=bool)\n",
    "for c in co.columns:\n",
    "    if c[0:len('exclusion_')]=='exclusion_':\n",
    "        N_REM = np.sum( (co[c].values==1) )\n",
    "        print('  {:5g} ({:2.2f}%) - {}'.format(N_REM,N_REM*100.0/co.shape[0], c))\n",
    "        idxRem[co[c].values==1] = True\n",
    "\n",
    "# summarize all exclusions\n",
    "N_REM = np.sum( idxRem )\n",
    "print('  {:5g} ({:2.2f}%) - {}'.format(N_REM,N_REM*100.0/co.shape[0], 'all exclusions'))\n",
    "print('')\n",
    "print('Final cohort size: {} ICU stays ({:2.2f}%).'.format(co.shape[0] - np.sum(idxRem), (1-np.mean(idxRem))*100.0))\n",
    "co = co.loc[~idxRem,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "death_48hr_post_icu_admit                1614 of 52085 died (3.10%).\n",
      "death_icu                                4185 of 52085 died (8.03%).\n",
      "death_in_hospital                        6192 of 52085 died (11.89%).\n",
      "death_30dy_post_icu_admit                7567 of 52085 died (14.53%).\n",
      "death_30dy_post_icu_disch                8081 of 52085 died (15.52%).\n",
      "death_30dy_post_hos_disch                8633 of 52085 died (16.57%).\n",
      "death_6mo_post_hos_disch                12788 of 52085 died (24.55%).\n",
      "death_1yr_post_hos_disch                15052 of 52085 died (28.90%).\n",
      "death_2yr_post_hos_disch                15052 of 52085 died (28.90%).\n",
      "death_30dy_post_hos_admit                7124 of 52085 died (13.68%).\n"
     ]
    }
   ],
   "source": [
    "# mortality stats\n",
    "for c in co.columns:\n",
    "    if c[0:len('death_')]=='death_':\n",
    "        N_ALL = co.shape[0]\n",
    "        N = co.set_index('icustay_id').loc[:,c].sum()\n",
    "        print('{:40s}{:5g} of {:5g} died ({:2.2f}%).'.format(c, N, N_ALL, N*100.0/N_ALL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize some datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "death_icu: 2020 of 23497 died (8.60%).\n",
      "death_in_hospital: 3034 of 23497 died (12.91%).\n"
     ]
    }
   ],
   "source": [
    "exclFcn = lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_stay_ge_24hr'],'icustay_id'].values\n",
    "\n",
    "y_outcome_label = 'death_icu'\n",
    "N_ALL = exclFcn(co).shape[0]\n",
    "N = co.set_index('icustay_id').loc[exclFcn(co),y_outcome_label].sum()\n",
    "print('{}: {} of {} died ({:2.2f}%).'.format(y_outcome_label, N, N_ALL, N*100.0/N_ALL))\n",
    "\n",
    "\n",
    "y_outcome_label = 'death_in_hospital'\n",
    "N_ALL = exclFcn(co).shape[0]\n",
    "N = co.set_index('icustay_id').loc[exclFcn(co),y_outcome_label].sum()\n",
    "print('{}: {} of {} died ({:2.2f}%).'.format(y_outcome_label, N, N_ALL, N*100.0/N_ALL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclusion criteria\n",
    "\n",
    "Each study has its own exclusion criteria (sometimes studies have multiple experiments). We define a dictionary of all exclusions with the dictionary key as the study name. Some studies have multiple experiments, so we append *a*, *b*, or *c*.\n",
    "\n",
    "The dictionary stores a length 2 list. The first element defines the window for data extraction: it contains a dictionary of the windows and the corresponding window sizes. The second element is the exclusion criteria. Both are functions which use `co` or `df` as their input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first we can define the different windows: there aren't that many!\n",
    "df_tmp=co.copy().set_index('icustay_id')\n",
    "\n",
    "# admission+12 hours\n",
    "time_12hr = df_tmp.copy()\n",
    "time_12hr['windowtime'] = 12\n",
    "time_12hr = time_12hr['windowtime'].to_dict()\n",
    "\n",
    "# admission+24 hours\n",
    "time_24hr = df_tmp.copy()\n",
    "time_24hr['windowtime'] = 24\n",
    "time_24hr = time_24hr['windowtime'].to_dict()\n",
    "\n",
    "# admission+48 hours\n",
    "time_48hr = df_tmp.copy()\n",
    "time_48hr['windowtime'] = 48\n",
    "time_48hr = time_48hr['windowtime'].to_dict()\n",
    "\n",
    "# admission+72 hours\n",
    "time_72hr = df_tmp.copy()\n",
    "time_72hr['windowtime'] = 72\n",
    "time_72hr = time_72hr['windowtime'].to_dict()\n",
    "\n",
    "# admission+96 hours\n",
    "time_96hr = df_tmp.copy()\n",
    "time_96hr['windowtime'] = 96\n",
    "time_96hr = time_96hr['windowtime'].to_dict()\n",
    "\n",
    "# entire stay\n",
    "time_all = df_tmp.copy()\n",
    "time_all = time_all['dischtime_hours'].apply(np.ceil).astype(int).to_dict()\n",
    "\n",
    "# 12 hours before the patient died/discharged\n",
    "time_predeath = df_tmp.copy()\n",
    "time_predeath['windowtime'] = time_predeath['dischtime_hours']\n",
    "idx = time_predeath['deathtime_hours']<time_predeath['dischtime_hours']\n",
    "time_predeath.loc[idx,'windowtime'] = time_predeath.loc[idx,'deathtime_hours']\n",
    "# move from discharge/death time to 12 hours beforehand\n",
    "time_predeath['windowtime'] = time_predeath['windowtime']-12\n",
    "time_predeath = time_predeath['windowtime'].apply(np.ceil).astype(int).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example params used to extract patient data\n",
    "# element 1: dictionary specifying end time of window for each patient\n",
    "# element 2: size of window\n",
    "# element 3: extra hours added to make it easier to get data on labs (and allows us to get labs pre-ICU)\n",
    "# e.g. [time_24hr, 8, 24] is\n",
    "#   (1) window ends at admission+24hr\n",
    "#   (2) window is 8 hours long\n",
    "#   (3) lab window is 8+24=32 hours long\n",
    "\n",
    "# this one is used more than once, so we define it here\n",
    "hugExclFcnMIMIC3 = lambda x: x.loc[x['inclusion_over_18']&x['inclusion_hug2009_obs']&x['inclusion_hug2009_not_nsicu_csicu']&x['inclusion_first_admission']&x['inclusion_full_code']&x['inclusion_not_brain_death']&x['inclusion_not_crf'],'icustay_id'].values\n",
    "hugExclFcn = lambda x: np.intersect1d(hugExclFcnMIMIC3(x),x.loc[x['inclusion_only_mimicii'],'icustay_id'].values)\n",
    "\n",
    "\n",
    "# physionet2012 subset - not exact but close\n",
    "def physChallExclFcn(x):\n",
    "    out = x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_stay_ge_48hr']&x['inclusion_has_saps'],'icustay_id'].values\n",
    "    out = np.sort(out)\n",
    "    out = out[0:4000]\n",
    "    return out\n",
    " \n",
    "# caballero2015 is a random subsample - then limits to 18yrs, resulting in 11648\n",
    "def caballeroExclFcn(x):\n",
    "    out = x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18'],'icustay_id'].values\n",
    "    out = np.sort(out)\n",
    "    out = out[0:11648]\n",
    "    return out\n",
    "\n",
    "np.random.seed(546345)\n",
    "W_extra = 24\n",
    "\n",
    "exclusions = OrderedDict([\n",
    "['caballero2015dynamically_a',  [[time_24hr, 24, W_extra], caballeroExclFcn, 'hospital_expire_flag']],\n",
    "['caballero2015dynamically_b',  [[time_48hr, 48, W_extra], caballeroExclFcn, 'hospital_expire_flag']],\n",
    "['caballero2015dynamically_c',  [[time_72hr, 72, W_extra], caballeroExclFcn, 'hospital_expire_flag']],\n",
    "['calvert2016computational',    [[time_predeath, 5, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_only_micu']&x['inclusion_calvert2016_obs']&x['inclusion_stay_ge_17hr']&x['inclusion_stay_le_500hr']&x['inclusion_non_alc_icd9'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['calvert2016using',            [[time_predeath, 5, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_only_micu']&x['inclusion_calvert2016_obs']&x['inclusion_stay_ge_17hr']&x['inclusion_stay_le_500hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['celi2012database_a',          [[time_72hr, 72, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_aki_icd9'],'icustay_id'].values , 'hospital_expire_flag']],\n",
    "['celi2012database_b',          [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_sah_icd9'],'icustay_id'].values , 'hospital_expire_flag']],\n",
    "['che2016recurrent_a',          [[time_48hr, 48, W_extra], lambda x: x.loc[x['inclusion_over_18'],'icustay_id'].values , 'death_48hr_post_icu_admit']],\n",
    "['che2016recurrent_b',          [[time_48hr, 48, W_extra], physChallExclFcn , 'hospital_expire_flag']],\n",
    "['ding2016mortality',           [[time_48hr, 48, W_extra], physChallExclFcn , 'hospital_expire_flag']],\n",
    "['ghassemi2014unfolding_a',     [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['ghassemi2014unfolding_b',     [[time_12hr, 12, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_stay_ge_12hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['ghassemi2014unfolding_c',     [[time_12hr, 12, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_stay_ge_12hr'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['ghassemi2014unfolding_d',     [[time_12hr, 12, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_stay_ge_12hr'],'icustay_id'].values, 'death_1yr_post_hos_disch']],\n",
    "['ghassemi2015multivariate_a',    [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_gt_6_notes']&x['inclusion_stay_ge_24hr']&x['inclusion_has_saps'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['ghassemi2015multivariate_b',    [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_gt_6_notes']&x['inclusion_stay_ge_24hr']&x['inclusion_has_saps'],'icustay_id'].values, 'death_1yr_post_hos_disch']],\n",
    "['grnarova2016neural_a',          [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_multiple_hadm'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['grnarova2016neural_b',          [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_multiple_hadm'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['grnarova2016neural_c',          [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_multiple_hadm'],'icustay_id'].values, 'death_1yr_post_hos_disch']],\n",
    "['harutyunyan2017multitask',    [[time_48hr, 48, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_multiple_icustay'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['hoogendoorn2016prediction',   [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_hug2009_obs']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['hug2009icu',                  [[time_24hr, 24, W_extra], hugExclFcn, 'death_30dy_post_icu_disch']],\n",
    "['johnson2012patient',          [[time_48hr, 48, W_extra], physChallExclFcn, 'hospital_expire_flag']],\n",
    "['johnson2014data',             [[time_48hr, 48, W_extra], physChallExclFcn, 'hospital_expire_flag']],\n",
    "['joshi2012prognostic',         [[time_24hr, 24, W_extra], hugExclFcn, 'hospital_expire_flag']],\n",
    "['joshi2016identifiable',       [[time_48hr, 48, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_stay_ge_48hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['lee2015customization_a',        [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_lee2015_service']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['lee2015customization_b',        [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_lee2015_service']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['lee2015customization_c',        [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_lee2015_service']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'death_2yr_post_hos_disch']],\n",
    "['lee2015personalized',         [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['lee2017patient',              [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['lehman2012risk',              [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr']&x['inclusion_first_admission'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['luo2016interpretable_a',        [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_sapsii']&x['inclusion_no_disch_summary'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['luo2016interpretable_b',        [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_sapsii']&x['inclusion_no_disch_summary'],'icustay_id'].values, 'death_6mo_post_hos_disch']],\n",
    "['luo2016predicting',           [[time_24hr, 12, W_extra], lambda x: np.intersect1d(hugExclFcn(x),x.loc[x['inclusion_stay_ge_24hr'],'icustay_id'].values) , 'death_30dy_post_icu_disch']],\n",
    "['pirracchio2015mortality',     [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii'],'icustay_id'].values , 'hospital_expire_flag']],\n",
    "['ripoll2014sepsis',            [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_saps']&x['inclusion_not_explicit_sepsis'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['wojtusiak2017c',              [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_over_65']&x['inclusion_alive_hos_disch'],'icustay_id'].values, 'death_30dy_post_hos_disch']]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define var_static which is used later\n",
    "#TODO: should refactor so this isn't needed\n",
    "var_min, var_max, var_first, var_last, var_sum, var_first_early, var_last_early, var_static = mp.vars_of_interest()\n",
    "\n",
    "K=5\n",
    "np.random.seed(871)\n",
    "# get unique subject_id (this is needed later)\n",
    "sid = np.sort(np.unique(df_death['subject_id'].values))\n",
    "\n",
    "# assign k-fold\n",
    "idxK_sid = np.random.permutation(sid.shape[0])\n",
    "idxK_sid = np.mod(idxK_sid,K)\n",
    "\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, df_death['subject_id'].values)\n",
    "\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== ========================== ==========\n",
      "========== BEGINNING caballero2015dynamically_a ==========\n",
      "==================== ========================== ==========\n",
      "Reducing sample size from 52050 to 11648 (22.38%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:44:51.776212 - Finished fold 1 of 5. AUROC 0.894.\n",
      "2017-08-14 17:44:55.553960 - Finished fold 2 of 5. AUROC 0.897.\n",
      "2017-08-14 17:44:59.239719 - Finished fold 3 of 5. AUROC 0.911.\n",
      "2017-08-14 17:45:03.917907 - Finished fold 4 of 5. AUROC 0.906.\n",
      "2017-08-14 17:45:08.400613 - Finished fold 5 of 5. AUROC 0.916.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:45:08.895601 - Finished fold 1 of 5. AUROC 0.881.\n",
      "2017-08-14 17:45:09.402869 - Finished fold 2 of 5. AUROC 0.885.\n",
      "2017-08-14 17:45:09.903320 - Finished fold 3 of 5. AUROC 0.882.\n",
      "2017-08-14 17:45:10.384137 - Finished fold 4 of 5. AUROC 0.891.\n",
      "2017-08-14 17:45:10.877482 - Finished fold 5 of 5. AUROC 0.901.\n",
      "\n",
      "==================== ========================== ==========\n",
      "========== BEGINNING caballero2015dynamically_b ==========\n",
      "==================== ========================== ==========\n",
      "Reducing sample size from 52050 to 11648 (22.38%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:45:28.537895 - Finished fold 1 of 5. AUROC 0.914.\n",
      "2017-08-14 17:45:33.222498 - Finished fold 2 of 5. AUROC 0.914.\n",
      "2017-08-14 17:45:37.600742 - Finished fold 3 of 5. AUROC 0.928.\n",
      "2017-08-14 17:45:42.864734 - Finished fold 4 of 5. AUROC 0.927.\n",
      "2017-08-14 17:45:47.063201 - Finished fold 5 of 5. AUROC 0.926.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:45:47.676944 - Finished fold 1 of 5. AUROC 0.892.\n",
      "2017-08-14 17:45:48.277807 - Finished fold 2 of 5. AUROC 0.904.\n",
      "2017-08-14 17:45:48.792200 - Finished fold 3 of 5. AUROC 0.901.\n",
      "2017-08-14 17:45:49.294283 - Finished fold 4 of 5. AUROC 0.914.\n",
      "2017-08-14 17:45:49.800710 - Finished fold 5 of 5. AUROC 0.913.\n",
      "\n",
      "==================== ========================== ==========\n",
      "========== BEGINNING caballero2015dynamically_c ==========\n",
      "==================== ========================== ==========\n",
      "Reducing sample size from 52050 to 11648 (22.38%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:46:08.234828 - Finished fold 1 of 5. AUROC 0.917.\n",
      "2017-08-14 17:46:12.622636 - Finished fold 2 of 5. AUROC 0.924.\n",
      "2017-08-14 17:46:17.767175 - Finished fold 3 of 5. AUROC 0.941.\n",
      "2017-08-14 17:46:21.709055 - Finished fold 4 of 5. AUROC 0.938.\n",
      "2017-08-14 17:46:25.831119 - Finished fold 5 of 5. AUROC 0.937.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:46:26.298549 - Finished fold 1 of 5. AUROC 0.900.\n",
      "2017-08-14 17:46:26.836735 - Finished fold 2 of 5. AUROC 0.918.\n",
      "2017-08-14 17:46:27.405124 - Finished fold 3 of 5. AUROC 0.912.\n",
      "2017-08-14 17:46:27.939660 - Finished fold 4 of 5. AUROC 0.927.\n",
      "2017-08-14 17:46:28.452371 - Finished fold 5 of 5. AUROC 0.922.\n",
      "\n",
      "==================== ======================== ==========\n",
      "========== BEGINNING calvert2016computational ==========\n",
      "==================== ======================== ==========\n",
      "Reducing sample size from 52042 to 1985 (3.81%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:46:32.288293 - Finished fold 1 of 5. AUROC 0.952.\n",
      "2017-08-14 17:46:32.957929 - Finished fold 2 of 5. AUROC 0.975.\n",
      "2017-08-14 17:46:33.559963 - Finished fold 3 of 5. AUROC 0.950.\n",
      "2017-08-14 17:46:34.328782 - Finished fold 4 of 5. AUROC 0.932.\n",
      "2017-08-14 17:46:35.008258 - Finished fold 5 of 5. AUROC 0.976.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:46:35.068501 - Finished fold 1 of 5. AUROC 0.907.\n",
      "2017-08-14 17:46:35.136190 - Finished fold 2 of 5. AUROC 0.943.\n",
      "2017-08-14 17:46:35.198858 - Finished fold 3 of 5. AUROC 0.925.\n",
      "2017-08-14 17:46:35.269920 - Finished fold 4 of 5. AUROC 0.860.\n",
      "2017-08-14 17:46:35.334463 - Finished fold 5 of 5. AUROC 0.920.\n",
      "\n",
      "==================== ================ ==========\n",
      "========== BEGINNING calvert2016using ==========\n",
      "==================== ================ ==========\n",
      "Reducing sample size from 52042 to 18396 (35.35%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:46:43.616897 - Finished fold 1 of 5. AUROC 0.924.\n",
      "2017-08-14 17:46:48.311165 - Finished fold 2 of 5. AUROC 0.941.\n",
      "2017-08-14 17:46:55.625777 - Finished fold 3 of 5. AUROC 0.935.\n",
      "2017-08-14 17:47:01.729712 - Finished fold 4 of 5. AUROC 0.935.\n",
      "2017-08-14 17:47:07.693283 - Finished fold 5 of 5. AUROC 0.933.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:47:08.569037 - Finished fold 1 of 5. AUROC 0.900.\n",
      "2017-08-14 17:47:09.481040 - Finished fold 2 of 5. AUROC 0.926.\n",
      "2017-08-14 17:47:10.317312 - Finished fold 3 of 5. AUROC 0.917.\n",
      "2017-08-14 17:47:11.279872 - Finished fold 4 of 5. AUROC 0.906.\n",
      "2017-08-14 17:47:12.267715 - Finished fold 5 of 5. AUROC 0.908.\n",
      "\n",
      "==================== ================== ==========\n",
      "========== BEGINNING celi2012database_a ==========\n",
      "==================== ================== ==========\n",
      "Reducing sample size from 52050 to 4741 (9.11%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:47:27.294988 - Finished fold 1 of 5. AUROC 0.871.\n",
      "2017-08-14 17:47:29.509880 - Finished fold 2 of 5. AUROC 0.880.\n",
      "2017-08-14 17:47:32.626015 - Finished fold 3 of 5. AUROC 0.882.\n",
      "2017-08-14 17:47:34.970001 - Finished fold 4 of 5. AUROC 0.890.\n",
      "2017-08-14 17:47:36.823857 - Finished fold 5 of 5. AUROC 0.889.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:47:36.951461 - Finished fold 1 of 5. AUROC 0.851.\n",
      "2017-08-14 17:47:37.098983 - Finished fold 2 of 5. AUROC 0.870.\n",
      "2017-08-14 17:47:37.239414 - Finished fold 3 of 5. AUROC 0.879.\n",
      "2017-08-14 17:47:37.397048 - Finished fold 4 of 5. AUROC 0.880.\n",
      "2017-08-14 17:47:37.580607 - Finished fold 5 of 5. AUROC 0.893.\n",
      "\n",
      "==================== ================== ==========\n",
      "========== BEGINNING celi2012database_b ==========\n",
      "==================== ================== ==========\n",
      "Reducing sample size from 52050 to 350 (0.67%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:47:42.960328 - Finished fold 1 of 5. AUROC 0.924.\n",
      "2017-08-14 17:47:43.263174 - Finished fold 2 of 5. AUROC 0.907.\n",
      "2017-08-14 17:47:43.633591 - Finished fold 3 of 5. AUROC 0.893.\n",
      "2017-08-14 17:47:43.931535 - Finished fold 4 of 5. AUROC 0.898.\n",
      "2017-08-14 17:47:44.285653 - Finished fold 5 of 5. AUROC 0.879.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:47:44.293886 - Finished fold 1 of 5. AUROC 0.887.\n",
      "2017-08-14 17:47:44.301715 - Finished fold 2 of 5. AUROC 0.809.\n",
      "2017-08-14 17:47:44.308989 - Finished fold 3 of 5. AUROC 0.824.\n",
      "2017-08-14 17:47:44.319237 - Finished fold 4 of 5. AUROC 0.824.\n",
      "2017-08-14 17:47:44.329727 - Finished fold 5 of 5. AUROC 0.849.\n",
      "\n",
      "==================== ================== ==========\n",
      "========== BEGINNING che2016recurrent_a ==========\n",
      "==================== ================== ==========\n",
      "Reducing sample size from 52050 to 51986 (99.88%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:48:11.483318 - Finished fold 1 of 5. AUROC 0.985.\n",
      "2017-08-14 17:48:30.576638 - Finished fold 2 of 5. AUROC 0.987.\n",
      "2017-08-14 17:48:46.969099 - Finished fold 3 of 5. AUROC 0.979.\n",
      "2017-08-14 17:49:04.948472 - Finished fold 4 of 5. AUROC 0.980.\n",
      "2017-08-14 17:49:20.851423 - Finished fold 5 of 5. AUROC 0.983.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:49:23.635867 - Finished fold 1 of 5. AUROC 0.962.\n",
      "2017-08-14 17:49:26.487120 - Finished fold 2 of 5. AUROC 0.963.\n",
      "2017-08-14 17:49:29.362557 - Finished fold 3 of 5. AUROC 0.957.\n",
      "2017-08-14 17:49:31.709438 - Finished fold 4 of 5. AUROC 0.965.\n",
      "2017-08-14 17:49:34.231760 - Finished fold 5 of 5. AUROC 0.961.\n",
      "\n",
      "==================== ================== ==========\n",
      "========== BEGINNING che2016recurrent_b ==========\n",
      "==================== ================== ==========\n",
      "Reducing sample size from 52050 to 4000 (7.68%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:49:45.858942 - Finished fold 1 of 5. AUROC 0.834.\n",
      "2017-08-14 17:49:47.712461 - Finished fold 2 of 5. AUROC 0.829.\n",
      "2017-08-14 17:49:48.927028 - Finished fold 3 of 5. AUROC 0.868.\n",
      "2017-08-14 17:49:50.129042 - Finished fold 4 of 5. AUROC 0.851.\n",
      "2017-08-14 17:49:51.464541 - Finished fold 5 of 5. AUROC 0.871.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:49:51.581936 - Finished fold 1 of 5. AUROC 0.798.\n",
      "2017-08-14 17:49:51.726810 - Finished fold 2 of 5. AUROC 0.837.\n",
      "2017-08-14 17:49:51.876710 - Finished fold 3 of 5. AUROC 0.850.\n",
      "2017-08-14 17:49:52.003258 - Finished fold 4 of 5. AUROC 0.852.\n",
      "2017-08-14 17:49:52.145324 - Finished fold 5 of 5. AUROC 0.838.\n",
      "\n",
      "==================== ================= ==========\n",
      "========== BEGINNING ding2016mortality ==========\n",
      "==================== ================= ==========\n",
      "Reducing sample size from 52050 to 4000 (7.68%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:50:04.511449 - Finished fold 1 of 5. AUROC 0.834.\n",
      "2017-08-14 17:50:06.117052 - Finished fold 2 of 5. AUROC 0.829.\n",
      "2017-08-14 17:50:07.736068 - Finished fold 3 of 5. AUROC 0.868.\n",
      "2017-08-14 17:50:09.230241 - Finished fold 4 of 5. AUROC 0.851.\n",
      "2017-08-14 17:50:10.845774 - Finished fold 5 of 5. AUROC 0.871.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:50:10.965566 - Finished fold 1 of 5. AUROC 0.798.\n",
      "2017-08-14 17:50:11.106097 - Finished fold 2 of 5. AUROC 0.837.\n",
      "2017-08-14 17:50:11.256382 - Finished fold 3 of 5. AUROC 0.850.\n",
      "2017-08-14 17:50:11.386060 - Finished fold 4 of 5. AUROC 0.852.\n",
      "2017-08-14 17:50:11.531423 - Finished fold 5 of 5. AUROC 0.838.\n",
      "\n",
      "==================== ======================= ==========\n",
      "========== BEGINNING ghassemi2014unfolding_a ==========\n",
      "==================== ======================= ==========\n",
      "Reducing sample size from 52050 to 23442 (45.04%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:50:24.374527 - Finished fold 1 of 5. AUROC 0.874.\n",
      "2017-08-14 17:50:32.026183 - Finished fold 2 of 5. AUROC 0.875.\n",
      "2017-08-14 17:50:40.148507 - Finished fold 3 of 5. AUROC 0.885.\n",
      "2017-08-14 17:50:47.559688 - Finished fold 4 of 5. AUROC 0.891.\n",
      "2017-08-14 17:50:58.015179 - Finished fold 5 of 5. AUROC 0.895.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:50:58.931335 - Finished fold 1 of 5. AUROC 0.856.\n",
      "2017-08-14 17:50:59.843360 - Finished fold 2 of 5. AUROC 0.863.\n",
      "2017-08-14 17:51:00.911658 - Finished fold 3 of 5. AUROC 0.863.\n",
      "2017-08-14 17:51:02.142884 - Finished fold 4 of 5. AUROC 0.874.\n",
      "2017-08-14 17:51:03.120511 - Finished fold 5 of 5. AUROC 0.874.\n",
      "\n",
      "==================== ======================= ==========\n",
      "========== BEGINNING ghassemi2014unfolding_b ==========\n",
      "==================== ======================= ==========\n",
      "Reducing sample size from 52050 to 28172 (54.12%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:51:17.735669 - Finished fold 1 of 5. AUROC 0.876.\n",
      "2017-08-14 17:51:27.171556 - Finished fold 2 of 5. AUROC 0.876.\n",
      "2017-08-14 17:51:36.347083 - Finished fold 3 of 5. AUROC 0.883.\n",
      "2017-08-14 17:51:45.360637 - Finished fold 4 of 5. AUROC 0.888.\n",
      "2017-08-14 17:51:54.460614 - Finished fold 5 of 5. AUROC 0.894.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:51:55.618122 - Finished fold 1 of 5. AUROC 0.849.\n",
      "2017-08-14 17:51:56.841801 - Finished fold 2 of 5. AUROC 0.857.\n",
      "2017-08-14 17:51:57.984022 - Finished fold 3 of 5. AUROC 0.859.\n",
      "2017-08-14 17:51:59.563722 - Finished fold 4 of 5. AUROC 0.872.\n",
      "2017-08-14 17:52:00.696661 - Finished fold 5 of 5. AUROC 0.870.\n",
      "\n",
      "==================== ======================= ==========\n",
      "========== BEGINNING ghassemi2014unfolding_c ==========\n",
      "==================== ======================= ==========\n",
      "Reducing sample size from 52050 to 28172 (54.12%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:52:14.502626 - Finished fold 1 of 5. AUROC 0.864.\n",
      "2017-08-14 17:52:24.027391 - Finished fold 2 of 5. AUROC 0.866.\n",
      "2017-08-14 17:52:33.591922 - Finished fold 3 of 5. AUROC 0.866.\n",
      "2017-08-14 17:52:42.561834 - Finished fold 4 of 5. AUROC 0.866.\n",
      "2017-08-14 17:52:51.523091 - Finished fold 5 of 5. AUROC 0.877.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:52:52.788710 - Finished fold 1 of 5. AUROC 0.837.\n",
      "2017-08-14 17:52:53.815488 - Finished fold 2 of 5. AUROC 0.847.\n",
      "2017-08-14 17:52:54.827604 - Finished fold 3 of 5. AUROC 0.845.\n",
      "2017-08-14 17:52:55.887006 - Finished fold 4 of 5. AUROC 0.843.\n",
      "2017-08-14 17:52:56.874046 - Finished fold 5 of 5. AUROC 0.850.\n",
      "\n",
      "==================== ======================= ==========\n",
      "========== BEGINNING ghassemi2014unfolding_d ==========\n",
      "==================== ======================= ==========\n",
      "Reducing sample size from 52050 to 28172 (54.12%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:53:10.486573 - Finished fold 1 of 5. AUROC 0.842.\n",
      "2017-08-14 17:53:20.200914 - Finished fold 2 of 5. AUROC 0.848.\n",
      "2017-08-14 17:53:29.773772 - Finished fold 3 of 5. AUROC 0.840.\n",
      "2017-08-14 17:53:39.307405 - Finished fold 4 of 5. AUROC 0.835.\n",
      "2017-08-14 17:53:48.944423 - Finished fold 5 of 5. AUROC 0.858.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:53:50.087762 - Finished fold 1 of 5. AUROC 0.811.\n",
      "2017-08-14 17:53:51.285480 - Finished fold 2 of 5. AUROC 0.822.\n",
      "2017-08-14 17:53:52.406955 - Finished fold 3 of 5. AUROC 0.819.\n",
      "2017-08-14 17:53:54.043891 - Finished fold 4 of 5. AUROC 0.813.\n",
      "2017-08-14 17:53:55.146142 - Finished fold 5 of 5. AUROC 0.833.\n",
      "\n",
      "==================== ========================== ==========\n",
      "========== BEGINNING ghassemi2015multivariate_a ==========\n",
      "==================== ========================== ==========\n",
      "Reducing sample size from 52050 to 21969 (42.21%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:54:08.114860 - Finished fold 1 of 5. AUROC 0.868.\n",
      "2017-08-14 17:54:16.287261 - Finished fold 2 of 5. AUROC 0.869.\n",
      "2017-08-14 17:54:26.050369 - Finished fold 3 of 5. AUROC 0.878.\n",
      "2017-08-14 17:54:35.336152 - Finished fold 4 of 5. AUROC 0.884.\n",
      "2017-08-14 17:54:43.855601 - Finished fold 5 of 5. AUROC 0.892.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:54:44.789690 - Finished fold 1 of 5. AUROC 0.849.\n",
      "2017-08-14 17:54:45.575993 - Finished fold 2 of 5. AUROC 0.857.\n",
      "2017-08-14 17:54:46.641194 - Finished fold 3 of 5. AUROC 0.857.\n",
      "2017-08-14 17:54:47.947462 - Finished fold 4 of 5. AUROC 0.868.\n",
      "2017-08-14 17:54:48.919558 - Finished fold 5 of 5. AUROC 0.871.\n",
      "\n",
      "==================== ========================== ==========\n",
      "========== BEGINNING ghassemi2015multivariate_b ==========\n",
      "==================== ========================== ==========\n",
      "Reducing sample size from 52050 to 21969 (42.21%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:55:01.905929 - Finished fold 1 of 5. AUROC 0.844.\n",
      "2017-08-14 17:55:10.060205 - Finished fold 2 of 5. AUROC 0.841.\n",
      "2017-08-14 17:55:17.940209 - Finished fold 3 of 5. AUROC 0.838.\n",
      "2017-08-14 17:55:25.579816 - Finished fold 4 of 5. AUROC 0.831.\n",
      "2017-08-14 17:55:33.578844 - Finished fold 5 of 5. AUROC 0.847.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:55:34.421068 - Finished fold 1 of 5. AUROC 0.823.\n",
      "2017-08-14 17:55:35.257533 - Finished fold 2 of 5. AUROC 0.816.\n",
      "2017-08-14 17:55:36.184081 - Finished fold 3 of 5. AUROC 0.818.\n",
      "2017-08-14 17:55:37.375828 - Finished fold 4 of 5. AUROC 0.811.\n",
      "2017-08-14 17:55:38.080839 - Finished fold 5 of 5. AUROC 0.827.\n",
      "\n",
      "==================== ==================== ==========\n",
      "========== BEGINNING grnarova2016neural_a ==========\n",
      "==================== ==================== ==========\n",
      "Reducing sample size from 52050 to 29572 (56.81%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:55:53.203918 - Finished fold 1 of 5. AUROC 0.979.\n",
      "2017-08-14 17:56:03.222418 - Finished fold 2 of 5. AUROC 0.984.\n",
      "2017-08-14 17:56:13.015026 - Finished fold 3 of 5. AUROC 0.980.\n",
      "2017-08-14 17:56:23.089200 - Finished fold 4 of 5. AUROC 0.982.\n",
      "2017-08-14 17:56:33.901911 - Finished fold 5 of 5. AUROC 0.982.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:56:35.107604 - Finished fold 1 of 5. AUROC 0.974.\n",
      "2017-08-14 17:56:36.282723 - Finished fold 2 of 5. AUROC 0.977.\n",
      "2017-08-14 17:56:37.544734 - Finished fold 3 of 5. AUROC 0.979.\n",
      "2017-08-14 17:56:38.724974 - Finished fold 4 of 5. AUROC 0.976.\n",
      "2017-08-14 17:56:39.885748 - Finished fold 5 of 5. AUROC 0.977.\n",
      "\n",
      "==================== ==================== ==========\n",
      "========== BEGINNING grnarova2016neural_b ==========\n",
      "==================== ==================== ==========\n",
      "Reducing sample size from 52050 to 29572 (56.81%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:56:57.551695 - Finished fold 1 of 5. AUROC 0.954.\n",
      "2017-08-14 17:57:10.636479 - Finished fold 2 of 5. AUROC 0.959.\n",
      "2017-08-14 17:57:23.224112 - Finished fold 3 of 5. AUROC 0.962.\n",
      "2017-08-14 17:57:34.180634 - Finished fold 4 of 5. AUROC 0.958.\n",
      "2017-08-14 17:57:45.971254 - Finished fold 5 of 5. AUROC 0.960.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:57:47.606423 - Finished fold 1 of 5. AUROC 0.948.\n",
      "2017-08-14 17:57:49.020290 - Finished fold 2 of 5. AUROC 0.953.\n",
      "2017-08-14 17:57:50.438315 - Finished fold 3 of 5. AUROC 0.955.\n",
      "2017-08-14 17:57:51.543644 - Finished fold 4 of 5. AUROC 0.954.\n",
      "2017-08-14 17:57:52.874083 - Finished fold 5 of 5. AUROC 0.954.\n",
      "\n",
      "==================== ==================== ==========\n",
      "========== BEGINNING grnarova2016neural_c ==========\n",
      "==================== ==================== ==========\n",
      "Reducing sample size from 52050 to 29572 (56.81%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:58:11.508064 - Finished fold 1 of 5. AUROC 0.911.\n",
      "2017-08-14 17:58:28.216569 - Finished fold 2 of 5. AUROC 0.911.\n",
      "2017-08-14 17:58:39.734719 - Finished fold 3 of 5. AUROC 0.914.\n",
      "2017-08-14 17:58:50.406023 - Finished fold 4 of 5. AUROC 0.907.\n",
      "2017-08-14 17:59:01.659803 - Finished fold 5 of 5. AUROC 0.914.\n",
      "=============== logreg ===============\n",
      "2017-08-14 17:59:03.092040 - Finished fold 1 of 5. AUROC 0.896.\n",
      "2017-08-14 17:59:04.238417 - Finished fold 2 of 5. AUROC 0.902.\n",
      "2017-08-14 17:59:05.465160 - Finished fold 3 of 5. AUROC 0.907.\n",
      "2017-08-14 17:59:06.670504 - Finished fold 4 of 5. AUROC 0.895.\n",
      "2017-08-14 17:59:07.855886 - Finished fold 5 of 5. AUROC 0.906.\n",
      "\n",
      "==================== ======================== ==========\n",
      "========== BEGINNING harutyunyan2017multitask ==========\n",
      "==================== ======================== ==========\n",
      "Reducing sample size from 52050 to 45493 (87.40%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 17:59:36.381662 - Finished fold 1 of 5. AUROC 0.933.\n",
      "2017-08-14 17:59:55.936537 - Finished fold 2 of 5. AUROC 0.949.\n",
      "2017-08-14 18:00:14.432543 - Finished fold 3 of 5. AUROC 0.938.\n",
      "2017-08-14 18:00:31.581820 - Finished fold 4 of 5. AUROC 0.940.\n",
      "2017-08-14 18:00:48.016906 - Finished fold 5 of 5. AUROC 0.941.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:00:50.050918 - Finished fold 1 of 5. AUROC 0.920.\n",
      "2017-08-14 18:00:52.126859 - Finished fold 2 of 5. AUROC 0.937.\n",
      "2017-08-14 18:00:54.192547 - Finished fold 3 of 5. AUROC 0.929.\n",
      "2017-08-14 18:00:56.297854 - Finished fold 4 of 5. AUROC 0.926.\n",
      "2017-08-14 18:00:58.442780 - Finished fold 5 of 5. AUROC 0.931.\n",
      "\n",
      "==================== ========================= ==========\n",
      "========== BEGINNING hoogendoorn2016prediction ==========\n",
      "==================== ========================= ==========\n",
      "Reducing sample size from 52050 to 17545 (33.71%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:01:12.615828 - Finished fold 1 of 5. AUROC 0.865.\n",
      "2017-08-14 18:01:19.089446 - Finished fold 2 of 5. AUROC 0.873.\n",
      "2017-08-14 18:01:27.045689 - Finished fold 3 of 5. AUROC 0.879.\n",
      "2017-08-14 18:01:35.608934 - Finished fold 4 of 5. AUROC 0.884.\n",
      "2017-08-14 18:01:42.991833 - Finished fold 5 of 5. AUROC 0.894.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:01:43.749613 - Finished fold 1 of 5. AUROC 0.850.\n",
      "2017-08-14 18:01:44.548083 - Finished fold 2 of 5. AUROC 0.858.\n",
      "2017-08-14 18:01:45.165084 - Finished fold 3 of 5. AUROC 0.861.\n",
      "2017-08-14 18:01:46.025413 - Finished fold 4 of 5. AUROC 0.868.\n",
      "2017-08-14 18:01:46.803337 - Finished fold 5 of 5. AUROC 0.876.\n",
      "\n",
      "==================== ========== ==========\n",
      "========== BEGINNING hug2009icu ==========\n",
      "==================== ========== ==========\n",
      "Reducing sample size from 52050 to 10696 (20.55%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:01:56.101520 - Finished fold 1 of 5. AUROC 0.854.\n",
      "2017-08-14 18:02:01.929770 - Finished fold 2 of 5. AUROC 0.852.\n",
      "2017-08-14 18:02:06.739310 - Finished fold 3 of 5. AUROC 0.858.\n",
      "2017-08-14 18:02:11.852292 - Finished fold 4 of 5. AUROC 0.825.\n",
      "2017-08-14 18:02:16.573018 - Finished fold 5 of 5. AUROC 0.885.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:02:17.168008 - Finished fold 1 of 5. AUROC 0.832.\n",
      "2017-08-14 18:02:17.517168 - Finished fold 2 of 5. AUROC 0.854.\n",
      "2017-08-14 18:02:17.974929 - Finished fold 3 of 5. AUROC 0.862.\n",
      "2017-08-14 18:02:18.344372 - Finished fold 4 of 5. AUROC 0.825.\n",
      "2017-08-14 18:02:18.744989 - Finished fold 5 of 5. AUROC 0.883.\n",
      "\n",
      "==================== ================== ==========\n",
      "========== BEGINNING johnson2012patient ==========\n",
      "==================== ================== ==========\n",
      "Reducing sample size from 52050 to 4000 (7.68%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:02:29.475066 - Finished fold 1 of 5. AUROC 0.834.\n",
      "2017-08-14 18:02:31.644370 - Finished fold 2 of 5. AUROC 0.829.\n",
      "2017-08-14 18:02:33.514069 - Finished fold 3 of 5. AUROC 0.868.\n",
      "2017-08-14 18:02:35.933706 - Finished fold 4 of 5. AUROC 0.851.\n",
      "2017-08-14 18:02:37.994387 - Finished fold 5 of 5. AUROC 0.871.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:02:38.116688 - Finished fold 1 of 5. AUROC 0.798.\n",
      "2017-08-14 18:02:38.260440 - Finished fold 2 of 5. AUROC 0.837.\n",
      "2017-08-14 18:02:38.409548 - Finished fold 3 of 5. AUROC 0.850.\n",
      "2017-08-14 18:02:38.544221 - Finished fold 4 of 5. AUROC 0.852.\n",
      "2017-08-14 18:02:38.688445 - Finished fold 5 of 5. AUROC 0.838.\n",
      "\n",
      "==================== =============== ==========\n",
      "========== BEGINNING johnson2014data ==========\n",
      "==================== =============== ==========\n",
      "Reducing sample size from 52050 to 4000 (7.68%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:02:49.108800 - Finished fold 1 of 5. AUROC 0.834.\n",
      "2017-08-14 18:02:51.590170 - Finished fold 2 of 5. AUROC 0.829.\n",
      "2017-08-14 18:02:53.547152 - Finished fold 3 of 5. AUROC 0.868.\n",
      "2017-08-14 18:02:55.440236 - Finished fold 4 of 5. AUROC 0.851.\n",
      "2017-08-14 18:02:57.315830 - Finished fold 5 of 5. AUROC 0.871.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:02:57.444072 - Finished fold 1 of 5. AUROC 0.798.\n",
      "2017-08-14 18:02:57.587786 - Finished fold 2 of 5. AUROC 0.837.\n",
      "2017-08-14 18:02:57.738973 - Finished fold 3 of 5. AUROC 0.850.\n",
      "2017-08-14 18:02:57.865420 - Finished fold 4 of 5. AUROC 0.852.\n",
      "2017-08-14 18:02:58.010872 - Finished fold 5 of 5. AUROC 0.838.\n",
      "\n",
      "==================== =================== ==========\n",
      "========== BEGINNING joshi2012prognostic ==========\n",
      "==================== =================== ==========\n",
      "Reducing sample size from 52050 to 10696 (20.55%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:03:05.798481 - Finished fold 1 of 5. AUROC 0.875.\n",
      "2017-08-14 18:03:11.148311 - Finished fold 2 of 5. AUROC 0.875.\n",
      "2017-08-14 18:03:17.137097 - Finished fold 3 of 5. AUROC 0.896.\n",
      "2017-08-14 18:03:21.622706 - Finished fold 4 of 5. AUROC 0.886.\n",
      "2017-08-14 18:03:27.013422 - Finished fold 5 of 5. AUROC 0.917.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:03:27.532114 - Finished fold 1 of 5. AUROC 0.854.\n",
      "2017-08-14 18:03:27.936925 - Finished fold 2 of 5. AUROC 0.876.\n",
      "2017-08-14 18:03:28.445156 - Finished fold 3 of 5. AUROC 0.872.\n",
      "2017-08-14 18:03:28.944655 - Finished fold 4 of 5. AUROC 0.877.\n",
      "2017-08-14 18:03:29.388389 - Finished fold 5 of 5. AUROC 0.899.\n",
      "\n",
      "==================== ===================== ==========\n",
      "========== BEGINNING joshi2016identifiable ==========\n",
      "==================== ===================== ==========\n",
      "Reducing sample size from 52050 to 26508 (50.93%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:03:47.459612 - Finished fold 1 of 5. AUROC 0.867.\n",
      "2017-08-14 18:03:57.520068 - Finished fold 2 of 5. AUROC 0.882.\n",
      "2017-08-14 18:04:07.521748 - Finished fold 3 of 5. AUROC 0.869.\n",
      "2017-08-14 18:04:17.738565 - Finished fold 4 of 5. AUROC 0.871.\n",
      "2017-08-14 18:04:28.204954 - Finished fold 5 of 5. AUROC 0.882.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:04:29.764063 - Finished fold 1 of 5. AUROC 0.844.\n",
      "2017-08-14 18:04:31.322008 - Finished fold 2 of 5. AUROC 0.861.\n",
      "2017-08-14 18:04:32.775133 - Finished fold 3 of 5. AUROC 0.849.\n",
      "2017-08-14 18:04:34.011577 - Finished fold 4 of 5. AUROC 0.852.\n",
      "2017-08-14 18:04:35.456457 - Finished fold 5 of 5. AUROC 0.867.\n",
      "\n",
      "==================== ====================== ==========\n",
      "========== BEGINNING lee2015customization_a ==========\n",
      "==================== ====================== ==========\n",
      "Reducing sample size from 52050 to 20961 (40.27%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:04:47.343572 - Finished fold 1 of 5. AUROC 0.870.\n",
      "2017-08-14 18:04:55.705133 - Finished fold 2 of 5. AUROC 0.874.\n",
      "2017-08-14 18:05:03.210186 - Finished fold 3 of 5. AUROC 0.884.\n",
      "2017-08-14 18:05:11.153294 - Finished fold 4 of 5. AUROC 0.891.\n",
      "2017-08-14 18:05:20.656326 - Finished fold 5 of 5. AUROC 0.890.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:05:21.502331 - Finished fold 1 of 5. AUROC 0.857.\n",
      "2017-08-14 18:05:22.368866 - Finished fold 2 of 5. AUROC 0.865.\n",
      "2017-08-14 18:05:23.335202 - Finished fold 3 of 5. AUROC 0.862.\n",
      "2017-08-14 18:05:24.563411 - Finished fold 4 of 5. AUROC 0.870.\n",
      "2017-08-14 18:05:25.415440 - Finished fold 5 of 5. AUROC 0.872.\n",
      "\n",
      "==================== ====================== ==========\n",
      "========== BEGINNING lee2015customization_b ==========\n",
      "==================== ====================== ==========\n",
      "Reducing sample size from 52050 to 20961 (40.27%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:05:38.703103 - Finished fold 1 of 5. AUROC 0.860.\n",
      "2017-08-14 18:05:46.827903 - Finished fold 2 of 5. AUROC 0.862.\n",
      "2017-08-14 18:05:54.325990 - Finished fold 3 of 5. AUROC 0.870.\n",
      "2017-08-14 18:06:03.567348 - Finished fold 4 of 5. AUROC 0.867.\n",
      "2017-08-14 18:06:11.640627 - Finished fold 5 of 5. AUROC 0.867.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:06:12.377779 - Finished fold 1 of 5. AUROC 0.843.\n",
      "2017-08-14 18:06:13.144385 - Finished fold 2 of 5. AUROC 0.850.\n",
      "2017-08-14 18:06:14.128436 - Finished fold 3 of 5. AUROC 0.854.\n",
      "2017-08-14 18:06:15.004548 - Finished fold 4 of 5. AUROC 0.849.\n",
      "2017-08-14 18:06:15.809460 - Finished fold 5 of 5. AUROC 0.852.\n",
      "\n",
      "==================== ====================== ==========\n",
      "========== BEGINNING lee2015customization_c ==========\n",
      "==================== ====================== ==========\n",
      "Reducing sample size from 52050 to 20961 (40.27%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:06:26.799263 - Finished fold 1 of 5. AUROC 0.847.\n",
      "2017-08-14 18:06:34.216592 - Finished fold 2 of 5. AUROC 0.844.\n",
      "2017-08-14 18:06:42.842823 - Finished fold 3 of 5. AUROC 0.845.\n",
      "2017-08-14 18:06:50.419920 - Finished fold 4 of 5. AUROC 0.835.\n",
      "2017-08-14 18:07:00.645109 - Finished fold 5 of 5. AUROC 0.850.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:07:01.442166 - Finished fold 1 of 5. AUROC 0.827.\n",
      "2017-08-14 18:07:02.238900 - Finished fold 2 of 5. AUROC 0.823.\n",
      "2017-08-14 18:07:03.121315 - Finished fold 3 of 5. AUROC 0.824.\n",
      "2017-08-14 18:07:04.215305 - Finished fold 4 of 5. AUROC 0.814.\n",
      "2017-08-14 18:07:05.083666 - Finished fold 5 of 5. AUROC 0.830.\n",
      "\n",
      "==================== =================== ==========\n",
      "========== BEGINNING lee2015personalized ==========\n",
      "==================== =================== ==========\n",
      "Reducing sample size from 52050 to 23443 (45.04%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:07:23.368190 - Finished fold 1 of 5. AUROC 0.863.\n",
      "2017-08-14 18:07:34.174743 - Finished fold 2 of 5. AUROC 0.864.\n",
      "2017-08-14 18:07:43.867223 - Finished fold 3 of 5. AUROC 0.869.\n",
      "2017-08-14 18:07:52.721991 - Finished fold 4 of 5. AUROC 0.869.\n",
      "2017-08-14 18:08:02.348844 - Finished fold 5 of 5. AUROC 0.870.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:08:03.162933 - Finished fold 1 of 5. AUROC 0.842.\n",
      "2017-08-14 18:08:03.997484 - Finished fold 2 of 5. AUROC 0.849.\n",
      "2017-08-14 18:08:04.911270 - Finished fold 3 of 5. AUROC 0.850.\n",
      "2017-08-14 18:08:05.954242 - Finished fold 4 of 5. AUROC 0.854.\n",
      "2017-08-14 18:08:06.764800 - Finished fold 5 of 5. AUROC 0.854.\n",
      "\n",
      "==================== ============== ==========\n",
      "========== BEGINNING lee2017patient ==========\n",
      "==================== ============== ==========\n",
      "Reducing sample size from 52050 to 23443 (45.04%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:08:19.798160 - Finished fold 1 of 5. AUROC 0.863.\n",
      "2017-08-14 18:08:29.181315 - Finished fold 2 of 5. AUROC 0.864.\n",
      "2017-08-14 18:08:38.152331 - Finished fold 3 of 5. AUROC 0.869.\n",
      "2017-08-14 18:08:45.985176 - Finished fold 4 of 5. AUROC 0.869.\n",
      "2017-08-14 18:08:54.335478 - Finished fold 5 of 5. AUROC 0.870.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:08:55.118439 - Finished fold 1 of 5. AUROC 0.842.\n",
      "2017-08-14 18:08:55.920015 - Finished fold 2 of 5. AUROC 0.849.\n",
      "2017-08-14 18:08:56.789995 - Finished fold 3 of 5. AUROC 0.850.\n",
      "2017-08-14 18:08:57.814957 - Finished fold 4 of 5. AUROC 0.854.\n",
      "2017-08-14 18:08:58.632276 - Finished fold 5 of 5. AUROC 0.854.\n",
      "\n",
      "==================== ============== ==========\n",
      "========== BEGINNING lehman2012risk ==========\n",
      "==================== ============== ==========\n",
      "Reducing sample size from 52050 to 21738 (41.76%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:09:08.920941 - Finished fold 1 of 5. AUROC 0.876.\n",
      "2017-08-14 18:09:16.147746 - Finished fold 2 of 5. AUROC 0.885.\n",
      "2017-08-14 18:09:23.934349 - Finished fold 3 of 5. AUROC 0.891.\n",
      "2017-08-14 18:09:32.321991 - Finished fold 4 of 5. AUROC 0.891.\n",
      "2017-08-14 18:09:40.365626 - Finished fold 5 of 5. AUROC 0.899.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:09:41.242488 - Finished fold 1 of 5. AUROC 0.856.\n",
      "2017-08-14 18:09:42.097652 - Finished fold 2 of 5. AUROC 0.872.\n",
      "2017-08-14 18:09:43.065315 - Finished fold 3 of 5. AUROC 0.869.\n",
      "2017-08-14 18:09:44.181263 - Finished fold 4 of 5. AUROC 0.875.\n",
      "2017-08-14 18:09:45.110419 - Finished fold 5 of 5. AUROC 0.880.\n",
      "\n",
      "==================== ====================== ==========\n",
      "========== BEGINNING luo2016interpretable_a ==========\n",
      "==================== ====================== ==========\n",
      "Reducing sample size from 52050 to 27747 (53.31%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:09:58.485879 - Finished fold 1 of 5. AUROC 0.926.\n",
      "2017-08-14 18:10:07.556803 - Finished fold 2 of 5. AUROC 0.926.\n",
      "2017-08-14 18:10:18.150345 - Finished fold 3 of 5. AUROC 0.930.\n",
      "2017-08-14 18:10:29.931350 - Finished fold 4 of 5. AUROC 0.933.\n",
      "2017-08-14 18:10:42.686577 - Finished fold 5 of 5. AUROC 0.927.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:10:43.716306 - Finished fold 1 of 5. AUROC 0.918.\n",
      "2017-08-14 18:10:44.769229 - Finished fold 2 of 5. AUROC 0.916.\n",
      "2017-08-14 18:10:45.901641 - Finished fold 3 of 5. AUROC 0.920.\n",
      "2017-08-14 18:10:47.282934 - Finished fold 4 of 5. AUROC 0.920.\n",
      "2017-08-14 18:10:48.573899 - Finished fold 5 of 5. AUROC 0.919.\n",
      "\n",
      "==================== ====================== ==========\n",
      "========== BEGINNING luo2016interpretable_b ==========\n",
      "==================== ====================== ==========\n",
      "Reducing sample size from 52050 to 27747 (53.31%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:11:03.887060 - Finished fold 1 of 5. AUROC 0.892.\n",
      "2017-08-14 18:11:19.550911 - Finished fold 2 of 5. AUROC 0.899.\n",
      "2017-08-14 18:11:30.997787 - Finished fold 3 of 5. AUROC 0.888.\n",
      "2017-08-14 18:11:44.171512 - Finished fold 4 of 5. AUROC 0.891.\n",
      "2017-08-14 18:11:56.136842 - Finished fold 5 of 5. AUROC 0.889.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:11:57.560841 - Finished fold 1 of 5. AUROC 0.876.\n",
      "2017-08-14 18:11:58.766262 - Finished fold 2 of 5. AUROC 0.879.\n",
      "2017-08-14 18:12:00.283050 - Finished fold 3 of 5. AUROC 0.874.\n",
      "2017-08-14 18:12:01.738090 - Finished fold 4 of 5. AUROC 0.880.\n",
      "2017-08-14 18:12:03.180746 - Finished fold 5 of 5. AUROC 0.875.\n",
      "\n",
      "==================== ================= ==========\n",
      "========== BEGINNING luo2016predicting ==========\n",
      "==================== ================= ==========\n",
      "Reducing sample size from 52050 to 8931 (17.16%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:12:09.420898 - Finished fold 1 of 5. AUROC 0.824.\n",
      "2017-08-14 18:12:13.425355 - Finished fold 2 of 5. AUROC 0.837.\n",
      "2017-08-14 18:12:18.469619 - Finished fold 3 of 5. AUROC 0.841.\n",
      "2017-08-14 18:12:21.772934 - Finished fold 4 of 5. AUROC 0.805.\n",
      "2017-08-14 18:12:26.786082 - Finished fold 5 of 5. AUROC 0.840.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:12:27.164464 - Finished fold 1 of 5. AUROC 0.812.\n",
      "2017-08-14 18:12:27.502052 - Finished fold 2 of 5. AUROC 0.851.\n",
      "2017-08-14 18:12:27.911993 - Finished fold 3 of 5. AUROC 0.836.\n",
      "2017-08-14 18:12:28.267536 - Finished fold 4 of 5. AUROC 0.798.\n",
      "2017-08-14 18:12:28.670679 - Finished fold 5 of 5. AUROC 0.845.\n",
      "\n",
      "==================== ======================= ==========\n",
      "========== BEGINNING pirracchio2015mortality ==========\n",
      "==================== ======================= ==========\n",
      "Reducing sample size from 52050 to 28795 (55.32%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:12:42.993505 - Finished fold 1 of 5. AUROC 0.899.\n",
      "2017-08-14 18:12:53.613802 - Finished fold 2 of 5. AUROC 0.900.\n",
      "2017-08-14 18:13:05.235255 - Finished fold 3 of 5. AUROC 0.910.\n",
      "2017-08-14 18:13:15.736570 - Finished fold 4 of 5. AUROC 0.909.\n",
      "2017-08-14 18:13:26.002588 - Finished fold 5 of 5. AUROC 0.916.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:13:27.139655 - Finished fold 1 of 5. AUROC 0.879.\n",
      "2017-08-14 18:13:28.316453 - Finished fold 2 of 5. AUROC 0.888.\n",
      "2017-08-14 18:13:29.457975 - Finished fold 3 of 5. AUROC 0.892.\n",
      "2017-08-14 18:13:30.934451 - Finished fold 4 of 5. AUROC 0.895.\n",
      "2017-08-14 18:13:32.097542 - Finished fold 5 of 5. AUROC 0.898.\n",
      "\n",
      "==================== ================ ==========\n",
      "========== BEGINNING ripoll2014sepsis ==========\n",
      "==================== ================ ==========\n",
      "Reducing sample size from 52050 to 2251 (4.32%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:13:36.770720 - Finished fold 1 of 5. AUROC 0.795.\n",
      "2017-08-14 18:13:37.952129 - Finished fold 2 of 5. AUROC 0.779.\n",
      "2017-08-14 18:13:39.129830 - Finished fold 3 of 5. AUROC 0.781.\n",
      "2017-08-14 18:13:40.748535 - Finished fold 4 of 5. AUROC 0.830.\n",
      "2017-08-14 18:13:43.270128 - Finished fold 5 of 5. AUROC 0.775.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:13:43.332273 - Finished fold 1 of 5. AUROC 0.746.\n",
      "2017-08-14 18:13:43.421001 - Finished fold 2 of 5. AUROC 0.776.\n",
      "2017-08-14 18:13:43.508624 - Finished fold 3 of 5. AUROC 0.765.\n",
      "2017-08-14 18:13:43.586397 - Finished fold 4 of 5. AUROC 0.798.\n",
      "2017-08-14 18:13:43.672873 - Finished fold 5 of 5. AUROC 0.800.\n",
      "\n",
      "==================== ============== ==========\n",
      "========== BEGINNING wojtusiak2017c ==========\n",
      "==================== ============== ==========\n",
      "Reducing sample size from 52050 to 22699 (43.61%).\n",
      "\n",
      "=============== xgb ===============\n",
      "2017-08-14 18:13:55.205990 - Finished fold 1 of 5. AUROC 0.800.\n",
      "2017-08-14 18:14:03.256274 - Finished fold 2 of 5. AUROC 0.782.\n",
      "2017-08-14 18:14:11.219229 - Finished fold 3 of 5. AUROC 0.801.\n",
      "2017-08-14 18:14:19.061680 - Finished fold 4 of 5. AUROC 0.815.\n",
      "2017-08-14 18:14:27.190413 - Finished fold 5 of 5. AUROC 0.786.\n",
      "=============== logreg ===============\n",
      "2017-08-14 18:14:28.392782 - Finished fold 1 of 5. AUROC 0.787.\n",
      "2017-08-14 18:14:29.302783 - Finished fold 2 of 5. AUROC 0.781.\n",
      "2017-08-14 18:14:30.384966 - Finished fold 3 of 5. AUROC 0.787.\n",
      "2017-08-14 18:14:31.592055 - Finished fold 4 of 5. AUROC 0.802.\n",
      "2017-08-14 18:14:32.778179 - Finished fold 5 of 5. AUROC 0.805.\n"
     ]
    }
   ],
   "source": [
    "mdl_val_all = dict()\n",
    "results_val_all = dict()\n",
    "pred_val_all = dict()\n",
    "tar_val_all = dict()\n",
    "\n",
    "# Rough timing info:\n",
    "#     rf - 3 seconds per fold\n",
    "#    xgb - 30 seconds per fold\n",
    "# logreg - 4 seconds per fold\n",
    "#  lasso - 8 seconds per fold\n",
    "models = OrderedDict([\n",
    "          ['xgb', xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)],\n",
    "          #['lasso', LassoCV(cv=5,fit_intercept=True,normalize=True,max_iter=10000)],\n",
    "          #['rf', RandomForestClassifier()],\n",
    "          ['logreg', LogisticRegression(fit_intercept=True)]\n",
    "         ])\n",
    "    \n",
    "with open('results.txt','w') as fp:\n",
    "    fp.write('StudyName,SampleSize,Outcome')\n",
    "    for mdl in models:\n",
    "        fp.write(',{}'.format(mdl))\n",
    "    fp.write('\\n')\n",
    "    \n",
    "for current_study in exclusions:    \n",
    "    print('\\n==================== {} =========='.format('='*len(current_study)))\n",
    "    print('========== BEGINNING {} =========='.format(current_study))\n",
    "    print('==================== {} =========='.format('='*len(current_study)))\n",
    "\n",
    "    params = exclusions[current_study][0]\n",
    "    df_data = mp.get_design_matrix(df, params[0], W=params[1], W_extra=params[2])\n",
    "\n",
    "    # get a list of icustay_id who stayed at least 12 hours\n",
    "    iid_keep = exclusions[current_study][1](co)\n",
    "    print('Reducing sample size from {} to {} ({:2.2f}%).'.format(\n",
    "            df_data.shape[0], iid_keep.shape[0], iid_keep.shape[0]*100.0 / df_data.shape[0]))\n",
    "    df_data = df_data.loc[iid_keep,:]\n",
    "    print('')\n",
    "\n",
    "    y_outcome_label = exclusions[current_study][2]\n",
    "    \n",
    "    # load the data into a numpy array\n",
    "\n",
    "    # first, the data from static vars from df_static\n",
    "    X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "    # next, add in the outcome: death in hospital\n",
    "    X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "\n",
    "    # map above K-fold indices to this dataset\n",
    "    X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "    # get indices which map subject_ids in sid to the X dataframe\n",
    "    idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "    # use these indices to map the k-fold integers\n",
    "    idxK = idxK_sid[idxMap]\n",
    "    # drop the subject_id column\n",
    "    X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "    # convert to numpy data (assumes target, death, is the last column)\n",
    "    X = X.values\n",
    "    y = X[:,-1]\n",
    "    X = X[:,0:-1]\n",
    "    X_header = [x for x in df_data.columns.values] + var_static\n",
    "    \n",
    "    mdl_val = dict()\n",
    "    results_val = dict()\n",
    "    pred_val = dict()\n",
    "    tar_val = dict()\n",
    "\n",
    "    for mdl in models:\n",
    "        print('=============== {} ==============='.format(mdl))\n",
    "        mdl_val[mdl] = list()\n",
    "        results_val[mdl] = list() # initialize list for scores\n",
    "        pred_val[mdl] = list()\n",
    "        tar_val[mdl] = list()\n",
    "\n",
    "        if mdl == 'xgb':\n",
    "            # no pre-processing of data necessary for xgb\n",
    "            estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "        else:\n",
    "            estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                              strategy=\"mean\",\n",
    "                                              axis=0)),\n",
    "                          (\"scaler\", StandardScaler()),\n",
    "                          (mdl, models[mdl])]) \n",
    "\n",
    "        for k in range(K):\n",
    "            # train the model using all but the kth fold\n",
    "            curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "            # get prediction on this dataset\n",
    "            if mdl == 'lasso':\n",
    "                curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "            else:\n",
    "                curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "                curr_prob = curr_prob[:,1]\n",
    "\n",
    "            pred_val[mdl].append(curr_prob)\n",
    "            tar_val[mdl].append(y[idxK == k])\n",
    "\n",
    "            # calculate score (AUROC)\n",
    "            curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "            # add score to list of scores\n",
    "            results_val[mdl].append(curr_score)\n",
    "\n",
    "            # save the current model\n",
    "            mdl_val[mdl].append(curr_mdl)\n",
    "\n",
    "            print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "\n",
    "    # create a pointer for above dicts with new var names\n",
    "    # we will likely re-use the dicts in subsequent calls for getting model perfomances\n",
    "    mdl_val_all[current_study] = mdl_val\n",
    "    results_val_all[current_study] = results_val\n",
    "    pred_val_all[current_study] = pred_val\n",
    "    tar_val_all[current_study] = tar_val\n",
    "    \n",
    "    # print to file\n",
    "    with open('results.txt','a') as fp:\n",
    "        # print study name, sample size and frequency of outcome\n",
    "        fp.write( '{},{},{:2.2f}'.format(current_study, X.shape[0], np.mean(y)*100.0 ) )\n",
    "        \n",
    "        for i, mdl in enumerate(models):\n",
    "            fp.write(',{:0.6f}'.format( np.mean(results_val[mdl]) ))\n",
    "        \n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run results for a single study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EXAMPLE_RUN=True\n",
    "\n",
    "# Rough timing info:\n",
    "#     rf - 3 seconds per fold\n",
    "#    xgb - 30 seconds per fold\n",
    "# logreg - 4 seconds per fold\n",
    "#  lasso - 8 seconds per fold\n",
    "models = OrderedDict([\n",
    "          ['xgb', xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)],\n",
    "          #['lasso', LassoCV(cv=5,fit_intercept=True,normalize=True,max_iter=10000)],\n",
    "          #['rf', RandomForestClassifier()],\n",
    "          ['logreg', LogisticRegression(fit_intercept=True)]\n",
    "         ])\n",
    "    \n",
    "if EXAMPLE_RUN:\n",
    "    current_study = 'celi2012database_b'\n",
    "    \n",
    "\n",
    "    print('')\n",
    "    print('====================={}==========='.format('='*len(current_study)))\n",
    "    print('========== BEGINNING {}==========='.format(current_study))\n",
    "    print('====================={}==========='.format('='*len(current_study)))\n",
    "\n",
    "    params = exclusions[current_study][0]\n",
    "    df_data = mp.get_design_matrix(df, params[0], W=params[1], W_extra=params[2])\n",
    "\n",
    "    # get a list of icustay_id who stayed at least 12 hours\n",
    "    iid_keep = exclusions[current_study][1](co)\n",
    "    print('Reducing sample size from {} to {} ({:2.2f}%).'.format(\n",
    "            df_data.shape[0], iid_keep.shape[0], iid_keep.shape[0]*100.0 / df_data.shape[0]))\n",
    "    df_data = df_data.loc[iid_keep,:]\n",
    "    print('')\n",
    "\n",
    "    y_outcome_label = exclusions[current_study][2]\n",
    "\n",
    "    # load the data into a numpy array\n",
    "\n",
    "    # first, the data from static vars from df_static\n",
    "    X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "    # next, add in the outcome: death in hospital\n",
    "    X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "\n",
    "    # map above K-fold indices to this dataset\n",
    "    X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "    # get indices which map subject_ids in sid to the X dataframe\n",
    "    idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "    # use these indices to map the k-fold integers\n",
    "    idxK = idxK_sid[idxMap]\n",
    "    # drop the subject_id column\n",
    "    X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "    # convert to numpy data (assumes target, death, is the last column)\n",
    "    X = X.values\n",
    "    y = X[:,-1]\n",
    "    X = X[:,0:-1]\n",
    "    X_header = [x for x in df_data.columns.values] + var_static\n",
    "    \n",
    "    mdl_val = dict()\n",
    "    results_val = dict()\n",
    "    pred_val = dict()\n",
    "    tar_val = dict()\n",
    "\n",
    "    for mdl in models:\n",
    "        print('=============== {} ==============='.format(mdl))\n",
    "        mdl_val[mdl] = list()\n",
    "        results_val[mdl] = list() # initialize list for scores\n",
    "        pred_val[mdl] = list()\n",
    "        tar_val[mdl] = list()\n",
    "\n",
    "        if mdl == 'xgb':\n",
    "            # no pre-processing of data necessary for xgb\n",
    "            estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "        else:\n",
    "            estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                              strategy=\"mean\",\n",
    "                                              axis=0)),\n",
    "                          (\"scaler\", StandardScaler()),\n",
    "                          (mdl, models[mdl])]) \n",
    "\n",
    "        for k in range(K):\n",
    "            # train the model using all but the kth fold\n",
    "            curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "            # get prediction on this dataset\n",
    "            if mdl == 'lasso':\n",
    "                curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "            else:\n",
    "                curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "                curr_prob = curr_prob[:,1]\n",
    "\n",
    "            pred_val[mdl].append(curr_prob)\n",
    "            tar_val[mdl].append(y[idxK == k])\n",
    "\n",
    "            # calculate score (AUROC)\n",
    "            curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "            # add score to list of scores\n",
    "            results_val[mdl].append(curr_score)\n",
    "\n",
    "            # save the current model\n",
    "            mdl_val[mdl].append(curr_mdl)\n",
    "\n",
    "            print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rough timing info:\n",
    "#     rf - 3 seconds per fold\n",
    "#    xgb - 30 seconds per fold\n",
    "# logreg - 4 seconds per fold\n",
    "#  lasso - 8 seconds per fold\n",
    "models = OrderedDict([\n",
    "          ['xgb', xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)],\n",
    "          #['lasso', LassoCV(cv=5,fit_intercept=True,normalize=True,max_iter=10000)],\n",
    "          #['rf', RandomForestClassifier()],\n",
    "          ['logreg', LogisticRegression(fit_intercept=True)]\n",
    "         ])\n",
    "current_study = 'baseline'\n",
    "\n",
    "print('')\n",
    "print('====================={}==========='.format('='*len(current_study)))\n",
    "print('========== BEGINNING {}==========='.format(current_study))\n",
    "print('====================={}==========='.format('='*len(current_study)))\n",
    "\n",
    "\n",
    "# admission+24 hours\n",
    "df_tmp=co.copy().set_index('icustay_id')\n",
    "time_dict = df_tmp.copy()\n",
    "time_dict['windowtime'] = 24\n",
    "time_dict = time_dict['windowtime'].to_dict()\n",
    "\n",
    "params = [time_dict, 24, 24]\n",
    "iid_keep = co['icustay_id'].values # include all icustays\n",
    "y_outcome_label = 'death_in_hospital'\n",
    "\n",
    "df_data = mp.get_design_matrix(df, params[0], W=params[1], W_extra=params[2])\n",
    "\n",
    "# get a list of icustay_id who stayed at least 12 hours\n",
    "N_NEW=df_data.loc[iid_keep,:].shape[0]\n",
    "print('Reducing sample size from {} to {} ({:2.2f}%).'.format(\n",
    "        co.shape[0], N_NEW, N_NEW*100.0 / co.shape[0]))\n",
    "df_data = df_data.loc[iid_keep,:]\n",
    "print('')\n",
    "\n",
    "# load the data into a numpy array\n",
    "\n",
    "# first, the data from static vars from df_static\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "# next, add in the outcome: death in hospital\n",
    "X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "\n",
    "# map above K-fold indices to this dataset\n",
    "X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]\n",
    "# drop the subject_id column\n",
    "X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "# convert to numpy data (assumes target, death, is the last column)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]\n",
    "X_header = [x for x in df_data.columns.values] + var_static\n",
    "\n",
    "mdl_val = dict()\n",
    "results_val = dict()\n",
    "pred_val = dict()\n",
    "tar_val = dict()\n",
    "\n",
    "for mdl in models:\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    mdl_val[mdl] = list()\n",
    "    results_val[mdl] = list() # initialize list for scores\n",
    "    pred_val[mdl] = list()\n",
    "    tar_val[mdl] = list()\n",
    "\n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])]) \n",
    "\n",
    "    for k in range(K):\n",
    "        # train the model using all but the kth fold\n",
    "        curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "        # get prediction on this dataset\n",
    "        if mdl == 'lasso':\n",
    "            curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "        else:\n",
    "            curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "            curr_prob = curr_prob[:,1]\n",
    "\n",
    "        pred_val[mdl].append(curr_prob)\n",
    "        tar_val[mdl].append(y[idxK == k])\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "\n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "        \n",
    "\n",
    "\n",
    "# print final results\n",
    "print('StudyName,SampleSize',end='')\n",
    "for mdl in models:\n",
    "    print(',{}'.format(mdl),end='')\n",
    "print('')\n",
    "\n",
    "print( '{},{}'.format(current_study, X.shape[0] ), end='' )\n",
    "\n",
    "for i, mdl in enumerate(models):\n",
    "    print(',{:0.6f}'.format( np.mean(results_val[mdl]) ), end='')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline no withdrawal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CENSOR_FLAG = True\n",
    "# Rough timing info:\n",
    "#     rf - 3 seconds per fold\n",
    "#    xgb - 30 seconds per fold\n",
    "# logreg - 4 seconds per fold\n",
    "#  lasso - 8 seconds per fold\n",
    "models = OrderedDict([\n",
    "          ['xgb', xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)],\n",
    "          #['lasso', LassoCV(cv=5,fit_intercept=True,normalize=True,max_iter=10000)],\n",
    "          ['logreg', LogisticRegression(fit_intercept=True)]\n",
    "          #['rf', RandomForestClassifier()]\n",
    "         ])\n",
    "current_study = 'baseline'\n",
    "\n",
    "print('\\n==================== {} =========='.format('='*len(current_study)))\n",
    "print('========== BEGINNING {} =========='.format(current_study))\n",
    "print('==================== {} =========='.format('='*len(current_study)))\n",
    "\n",
    "\n",
    "# admission+24 hours\n",
    "df_tmp=co.copy().set_index('icustay_id')\n",
    "time_dict = df_tmp.copy()\n",
    "time_dict['windowtime'] = 24\n",
    "time_dict = time_dict['windowtime'].to_dict()\n",
    "\n",
    "    \n",
    "    \n",
    "params = [time_dict, 24, 24]\n",
    "# optionally remove patients who were DNR in first 24hrs\n",
    "if CENSOR_FLAG:\n",
    "    idx = (df_tmp['censortime_hours'].isnull()) | (df_tmp['censortime_hours']>=24)\n",
    "    iid_keep = df_tmp.loc[idx, :].index.values\n",
    "else:\n",
    "    iid_keep = df_tmp['icustay_id'].values # include all icustays\n",
    "y_outcome_label = 'death_in_hospital'\n",
    "\n",
    "df_data = mp.get_design_matrix(df, params[0], W=params[1], W_extra=params[2])\n",
    "\n",
    "# get a list of icustay_id who stayed at least 12 hours\n",
    "N_NEW=df_data.loc[iid_keep,:].shape[0]\n",
    "print('Reducing sample size from {} to {} ({:2.2f}%).'.format(\n",
    "        co.shape[0], N_NEW, N_NEW*100.0 / co.shape[0]))\n",
    "df_data = df_data.loc[iid_keep,:]\n",
    "print('')\n",
    "\n",
    "# load the data into a numpy array\n",
    "\n",
    "# first, the data from static vars from df_static\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "# next, add in the outcome: death in hospital\n",
    "X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "\n",
    "# map above K-fold indices to this dataset\n",
    "X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]\n",
    "# drop the subject_id column\n",
    "X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "# convert to numpy data (assumes target, death, is the last column)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]\n",
    "X_header = [x for x in df_data.columns.values] + var_static\n",
    "\n",
    "mdl_val = dict()\n",
    "results_val = dict()\n",
    "pred_val = dict()\n",
    "tar_val = dict()\n",
    "\n",
    "for mdl in models:\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    mdl_val[mdl] = list()\n",
    "    results_val[mdl] = list() # initialize list for scores\n",
    "    pred_val[mdl] = list()\n",
    "    tar_val[mdl] = list()\n",
    "\n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])]) \n",
    "\n",
    "    for k in range(K):\n",
    "        # train the model using all but the kth fold\n",
    "        curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "        # get prediction on this dataset\n",
    "        if mdl == 'lasso':\n",
    "            curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "        else:\n",
    "            curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "            curr_prob = curr_prob[:,1]\n",
    "\n",
    "        pred_val[mdl].append(curr_prob)\n",
    "        tar_val[mdl].append(y[idxK == k])\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "\n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "        \n",
    "\n",
    "\n",
    "# print final results\n",
    "print('StudyName,SampleSize',end='')\n",
    "for mdl in models:\n",
    "    print(',{}'.format(mdl),end='')\n",
    "print('')\n",
    "\n",
    "print( '{},{}'.format(current_study, X.shape[0] ), end='' )\n",
    "\n",
    "for i, mdl in enumerate(models):\n",
    "    print(',{:0.6f}'.format( np.mean(results_val[mdl]) ), end='')\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CENSOR_FLAG = True\n",
    "# Rough timing info:\n",
    "#     rf - 3 seconds per fold\n",
    "#    xgb - 30 seconds per fold\n",
    "# logreg - 4 seconds per fold\n",
    "#  lasso - 8 seconds per fold\n",
    "models = OrderedDict([\n",
    "          ['xgb', xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)],\n",
    "          #['lasso', LassoCV(cv=5,fit_intercept=True,normalize=True,max_iter=10000)],\n",
    "          ['logreg', LogisticRegression(fit_intercept=True)]\n",
    "          #['rf', RandomForestClassifier()]\n",
    "         ])\n",
    "current_study = 'baseline_withdrawal'\n",
    "\n",
    "print('====================={}==========='.format('='*len(current_study)))\n",
    "print('========== BEGINNING {} =========='.format(current_study))\n",
    "print('====================={}==========='.format('='*len(current_study)))\n",
    "\n",
    "\n",
    "# admission+24 hours\n",
    "df_tmp=co.copy().set_index('icustay_id')\n",
    "time_dict = df_tmp.copy()\n",
    "time_dict['windowtime'] = 24\n",
    "time_dict = time_dict['windowtime'].to_dict()\n",
    "\n",
    "# optionally remove patients who were DNR in first 24hrs\n",
    "if CENSOR_FLAG:\n",
    "    exclFcn = lambda x: x.loc[x['inclusion_stay_ge_24hr']& ( (x['censortime_hours'].isnull()) | (x['censortime_hours']>=24) ) ,'icustay_id'].values\n",
    "else:\n",
    "    exclFcn = lambda x: x.loc[x['inclusion_stay_ge_24hr']& ( (x['censortime_hours'].isnull()) | (x['censortime_hours']>=24) ) ,'icustay_id'].values\n",
    "    \n",
    "y_outcome_label = 'death_in_hospital'\n",
    "df_data = mp.get_design_matrix(df, params[0], W=params[1], W_extra=params[2])\n",
    "\n",
    "iid_keep = exclFcn(co)\n",
    "N_NEW=df_data.loc[iid_keep,:].shape[0]\n",
    "\n",
    "print('Reducing sample size from {} to {} ({:2.2f}%).'.format(\n",
    "        co.shape[0], N_NEW, N_NEW*100.0 / df_data.shape[0]))\n",
    "df_data = df_data.loc[iid_keep,:]\n",
    "print('')\n",
    "\n",
    "# load the data into a numpy array\n",
    "\n",
    "# first, the data from static vars from df_static\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "# next, add in the outcome: death in hospital\n",
    "X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "\n",
    "# map above K-fold indices to this dataset\n",
    "X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]\n",
    "# drop the subject_id column\n",
    "X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "# convert to numpy data (assumes target, death, is the last column)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]\n",
    "X_header = [x for x in df_data.columns.values] + var_static\n",
    "\n",
    "mdl_val = dict()\n",
    "results_val = dict()\n",
    "pred_val = dict()\n",
    "tar_val = dict()\n",
    "\n",
    "for mdl in models:\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    mdl_val[mdl] = list()\n",
    "    results_val[mdl] = list() # initialize list for scores\n",
    "    pred_val[mdl] = list()\n",
    "    tar_val[mdl] = list()\n",
    "\n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])]) \n",
    "\n",
    "    for k in range(K):\n",
    "        # train the model using all but the kth fold\n",
    "        curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "        # get prediction on this dataset\n",
    "        if mdl == 'lasso':\n",
    "            curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "        else:\n",
    "            curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "            curr_prob = curr_prob[:,1]\n",
    "\n",
    "        pred_val[mdl].append(curr_prob)\n",
    "        tar_val[mdl].append(y[idxK == k])\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "\n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "        \n",
    "\n",
    "\n",
    "# print final results\n",
    "print('StudyName,SampleSize',end='')\n",
    "for mdl in models:\n",
    "    print(',{}'.format(mdl),end='')\n",
    "print('')\n",
    "\n",
    "print( '{},{}'.format(current_study, X.shape[0] ), end='' )\n",
    "\n",
    "for i, mdl in enumerate(models):\n",
    "    print(',{:0.6f}'.format( np.mean(results_val[mdl]) ), end='')\n",
    "\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
